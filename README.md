# üìö Conjunto de Datos de Clasificaci√≥n de Temas de AG News

### üë• Realizado por:
- **Diego Alexander Parra**  
- **Juan Camilo Ortiz**  

---

## üöÄ Introducci√≥n

El **conjunto de datos AG News** es una colecci√≥n de m√°s de 1 mill√≥n de art√≠culos de noticias, recopilados de m√°s de 2000 fuentes por *ComeToMyHead* durante un a√±o. *ComeToMyHead* es un motor de b√∫squeda de noticias acad√©micas en funcionamiento desde julio de 2004.

Este conjunto de datos se proporciona a la comunidad acad√©mica para fines de investigaci√≥n en √°reas como:
- **Miner√≠a de datos:** clustering, clasificaci√≥n
- **Recuperaci√≥n de informaci√≥n:** ranking, b√∫squeda
- **Otras aplicaciones:** XML, compresi√≥n y transmisi√≥n de datos

[**M√°s informaci√≥n aqu√≠**](http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html).

El **conjunto de datos de Clasificaci√≥n de Temas de AG News** fue curado por **Xiang Zhang** (*xiang.zhang@nyu.edu*) a partir del corpus original. Este conjunto se utiliz√≥ como referente en el art√≠culo:

- *Xiang Zhang, Junbo Zhao, Yann LeCun. Redes Neuronales Convolucionales a Nivel de Caracteres para la Clasificaci√≥n de Textos. Avances en Sistemas de Procesamiento de Informaci√≥n Neural 28 (NIPS 2015).*  

---

## üìä Descripci√≥n del Conjunto de Datos

El conjunto de datos se centra en las **cuatro categor√≠as m√°s grandes** del corpus original:

- üåç **Mundo**  
- üèÖ **Deportes**  
- üíº **Negocios**  
- üî¨ **Ciencia/Tecnolog√≠a**  

### üì¶ Estructura del Conjunto de Datos
- **Conjunto de Entrenamiento:** 120,000 muestras (30,000 por clase)
- **Conjunto de Prueba:** 7,600 muestras (1,900 por clase)

### üìÇ Detalles de los Archivos
- **`classes.txt`**: Lista de clases correspondientes a cada etiqueta.
- **`train.csv` y `test.csv`**: Muestras de entrenamiento y prueba en formato CSV.

Cada archivo CSV incluye:
1. **üî¢ √çndice de Clase (1 a 4)**
2. **üìÑ T√≠tulo del Art√≠culo**
3. **üí∞ Descripci√≥n del Art√≠culo**

> *Nota:* Los t√≠tulos y descripciones est√°n entrecomillados (`" "`). Las comillas internas se escapan con comillas dobles (`""`). Los saltos de l√≠nea se representan como `\n`.

---

## ‚öôÔ∏è Metodolog√≠a

### 1Ô∏è‚É£ Preprocesamiento de Datos
- **Tokenizaci√≥n y Relleno:** Estandarizaci√≥n de la longitud de las secuencias de entrada.
- **Codificaci√≥n One-Hot:** Transformaci√≥n de variables categ√≥ricas.

### 2Ô∏è‚É£ Arquitectura del Modelo
- **LSTM (Long Short-Term Memory):** Capaz de manejar dependencias a largo plazo.
- **GRU (Gated Recurrent Unit):** Alternativa eficiente al LSTM.
- **Transformer (Atenci√≥n de Cabeza √önica):** Captura relaciones contextuales.
- **Transformer (Atenci√≥n Multi-Cabezal - 4 Cabezas):** Mejora el procesamiento paralelo de la atenci√≥n.

---

## üìà Resultados

El rendimiento de cada modelo se evalu√≥ usando **Precisi√≥n**, **Recall** y **F1-Score**.

### üîç Comparaci√≥n General
- **LSTM y GRU:** Alcanzaron una **precisi√≥n del 91%** y puntuaciones F1 de **0.91**, mostrando alto rendimiento.
- **Transformers (1 y 4 Cabezas):** Precisi√≥n del **90%** con F1 de **0.90**, ligeramente inferior a LSTM y GRU.

### üèÜ Rendimiento por Categor√≠a
- **Deportes:** Mejor rendimiento, F1 de **0.97** (GRU) y **0.96** (otros modelos).
- **Negocios:** Rendimiento m√°s bajo, especialmente en el Transformer de 4 cabezas (F1: **0.86**).
- **Ciencia/Tecnolog√≠a:** Rendimiento estable, F1 entre **0.87** y **0.88**.

### ‚ö° Impacto de Cabezas de Atenci√≥n en Transformers
- Aumentar de **1 a 4 cabezas** **no mejor√≥ significativamente el rendimiento**. En algunos casos, hubo ligeras disminuciones, como en la categor√≠a de Negocios (de **0.86** a **0.84**).

---

## ‚úÖ Conclusiones

- **LSTM y GRU** demostraron ser altamente efectivos, con GRU destacando por su eficiencia computacional.
- Aunque los **Transformers** son potentes en tareas complejas, **no superaron** a los modelos basados en RNN en este escenario.
- El **n√∫mero de cabezas de atenci√≥n** en Transformers **no garantiz√≥ mejoras** significativas.

---

## üí° Recomendaciones

1. **Ajuste de Hiperpar√°metros:** Explorar configuraciones para optimizar el rendimiento de los Transformers.
2. **Embeddings Preentrenados:** Utilizar modelos de embeddings para mejorar la comprensi√≥n sem√°ntica.
3. **Aumento de Datos:** Implementar t√©cnicas de aumento para mejorar el rendimiento, especialmente en categor√≠as m√°s desafiantes como *Negocios*.



