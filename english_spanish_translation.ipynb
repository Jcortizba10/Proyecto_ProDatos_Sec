{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pbzgtF6qbWN",
        "outputId": "3cd392d1-12fe-431c-fb52-5e0405e30c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ic5Oa3h_hXf"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Deep Learning/Proyecto1/data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbMBawVZBC66",
        "outputId": "a234c3de-25e2-426c-b46f-ad720ff04910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 118964 entries, 0 to 118963\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   english  118964 non-null  object\n",
            " 1   spanish  118964 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5T8lDrzABKdh",
        "outputId": "96f6939c-90a4-43a6-c938-0953f7ecb1ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  english  \\\n",
              "0                                                     Go.   \n",
              "1                                                     Go.   \n",
              "2                                                     Go.   \n",
              "3                                                     Go.   \n",
              "4                                                     Hi.   \n",
              "...                                                   ...   \n",
              "118959  There are four main causes of alcohol-related ...   \n",
              "118960  There are mothers and fathers who will lie awa...   \n",
              "118961  A carbon footprint is the amount of carbon dio...   \n",
              "118962  Since there are usually multiple websites on a...   \n",
              "118963  If you want to sound like a native speaker, yo...   \n",
              "\n",
              "                                                  spanish  \n",
              "0                                                     Ve.  \n",
              "1                                                   Vete.  \n",
              "2                                                   Vaya.  \n",
              "3                                                 Váyase.  \n",
              "4                                                   Hola.  \n",
              "...                                                   ...  \n",
              "118959  Hay cuatro causas principales de muertes relac...  \n",
              "118960  Hay madres y padres que se quedan despiertos d...  \n",
              "118961  Una huella de carbono es la cantidad de contam...  \n",
              "118962  Como suele haber varias páginas web sobre cual...  \n",
              "118963  Si quieres sonar como un hablante nativo, debe...  \n",
              "\n",
              "[118964 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50ac983d-c6f4-45b7-b308-873bd47dbc9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>spanish</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Ve.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vete.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vaya.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Váyase.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Hola.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118959</th>\n",
              "      <td>There are four main causes of alcohol-related ...</td>\n",
              "      <td>Hay cuatro causas principales de muertes relac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118960</th>\n",
              "      <td>There are mothers and fathers who will lie awa...</td>\n",
              "      <td>Hay madres y padres que se quedan despiertos d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118961</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Una huella de carbono es la cantidad de contam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118962</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Como suele haber varias páginas web sobre cual...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118963</th>\n",
              "      <td>If you want to sound like a native speaker, yo...</td>\n",
              "      <td>Si quieres sonar como un hablante nativo, debe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>118964 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50ac983d-c6f4-45b7-b308-873bd47dbc9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50ac983d-c6f4-45b7-b308-873bd47dbc9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50ac983d-c6f4-45b7-b308-873bd47dbc9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df914ccf-1ac0-48d7-9d30-807531d949c1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df914ccf-1ac0-48d7-9d30-807531d949c1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df914ccf-1ac0-48d7-9d30-807531d949c1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_90f6a114-69ef-4ef0-8350-3799616a7cd3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_90f6a114-69ef-4ef0-8350-3799616a7cd3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Yg0UNd7NH_"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb0WneBi7PxO"
      },
      "outputs": [],
      "source": [
        "# Importar librerías de procesamiento de texto y modelado\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Attention, Concatenate\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Parámetros globales\n",
        "#LATENT_DIM = 256\n",
        "#BATCH_SIZE = 64\n",
        "#EPOCHS = 8\n",
        "# Parámetros del modelo\n",
        "LATENT_DIM = 256\n",
        "input_vocab_size = 23849  # Tamaño del vocabulario en inglés\n",
        "target_vocab_size = 41724  # Tamaño del vocabulario en español\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLi2hQlP7QxS",
        "outputId": "edb946ad-e893-45e3-8349-a7173e48bd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron valores nulos.\n",
            "\n",
            "Ejemplo de datos:\n",
            "  english  spanish\n",
            "0     Go.      Ve.\n",
            "1     Go.    Vete.\n",
            "2     Go.    Vaya.\n",
            "3     Go.  Váyase.\n",
            "4     Hi.    Hola.\n"
          ]
        }
      ],
      "source": [
        "# Verificar valores nulos\n",
        "if dataset.isnull().sum().any():\n",
        "    print(\"Advertencia: Existen valores nulos en el dataset.\")\n",
        "    dataset = dataset.dropna()\n",
        "else:\n",
        "    print(\"No se encontraron valores nulos.\")\n",
        "\n",
        "# Previsualizar datos\n",
        "print(\"\\nEjemplo de datos:\")\n",
        "print(dataset.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sziJvKLY7e0R",
        "outputId": "b4378ab7-f82e-4742-dd38-5d24ba91ef82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario (inglés): 23849\n",
            "Tamaño del vocabulario (español): 41724\n"
          ]
        }
      ],
      "source": [
        "# Preparar los datos\n",
        "input_texts = dataset['english'].values\n",
        "target_texts = ['<start> ' + text + ' <end>' for text in dataset['spanish'].values]\n",
        "\n",
        "# Tokenización para inglés\n",
        "tokenizer_eng = Tokenizer(filters='')\n",
        "tokenizer_eng.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_eng.texts_to_sequences(input_texts)\n",
        "input_sequences = pad_sequences(input_sequences, padding='post')\n",
        "\n",
        "# Tokenización para español\n",
        "tokenizer_spa = Tokenizer(filters='')\n",
        "tokenizer_spa.fit_on_texts(target_texts)\n",
        "target_sequences = tokenizer_spa.texts_to_sequences(target_texts)\n",
        "target_sequences = pad_sequences(target_sequences, padding='post')\n",
        "\n",
        "# Vocabulario\n",
        "input_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "target_vocab_size = len(tokenizer_spa.word_index) + 1\n",
        "\n",
        "print(f\"Tamaño del vocabulario (inglés): {input_vocab_size}\")\n",
        "print(f\"Tamaño del vocabulario (español): {target_vocab_size}\")\n",
        "\n",
        "# Dividir datos en entrenamiento y validación\n",
        "input_train, input_val, target_train, target_val = train_test_split(\n",
        "    input_sequences, target_sequences, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "MVTB_Tpf7ig_",
        "outputId": "d793c8df-eac7-435d-cf01-be5acfdd8fa3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m6,105,344\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m10,681,344\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │        \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41724\u001b[0m)    │     \u001b[38;5;34m21,404,412\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,344</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,681,344</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41724</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">21,404,412</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,241,724\u001b[0m (149.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,241,724</span> (149.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,241,724\u001b[0m (149.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,241,724</span> (149.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Crear entradas y salidas para el decodificador\n",
        "decoder_input_train = np.array([seq[:-1] for seq in target_train])\n",
        "decoder_target_train = np.array([seq[1:] for seq in target_train])\n",
        "decoder_input_val = np.array([seq[:-1] for seq in target_val])\n",
        "decoder_target_val = np.array([seq[1:] for seq in target_val])\n",
        "\n",
        "# Construcción del modelo\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_vocab_size, LATENT_DIM)(encoder_inputs)\n",
        "encoder_lstm_outputs, state_h, state_c = LSTM(LATENT_DIM, return_state=True, return_sequences=True)(encoder_embedding)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(target_vocab_size, LATENT_DIM)(decoder_inputs)\n",
        "decoder_lstm_outputs, _, _ = LSTM(LATENT_DIM, return_sequences=True, return_state=True)(decoder_embedding, initial_state=encoder_states)\n",
        "\n",
        "# Atención\n",
        "attention = Attention()\n",
        "context_vector = attention([decoder_lstm_outputs, encoder_lstm_outputs])\n",
        "\n",
        "# Concatenación del contexto con la salida del decodificador\n",
        "concat_layer = Concatenate(axis=-1)([context_vector, decoder_lstm_outputs])\n",
        "\n",
        "# Capa densa para la predicción final\n",
        "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(concat_layer)\n",
        "\n",
        "# Modelo completo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "DtksaIsi7o40",
        "outputId": "d835dccc-9c33-4b80-8ca7-d070c4aee8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 334ms/step - loss: 1.2298 - sparse_categorical_accuracy: 0.8759 - val_loss: 0.6744 - val_sparse_categorical_accuracy: 0.9020\n",
            "Epoch 2/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 343ms/step - loss: 0.6011 - sparse_categorical_accuracy: 0.9084 - val_loss: 0.4876 - val_sparse_categorical_accuracy: 0.9244\n",
            "Epoch 3/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 344ms/step - loss: 0.4018 - sparse_categorical_accuracy: 0.9304 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.9370\n",
            "Epoch 4/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 346ms/step - loss: 0.2741 - sparse_categorical_accuracy: 0.9465 - val_loss: 0.3619 - val_sparse_categorical_accuracy: 0.9425\n",
            "Epoch 5/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 347ms/step - loss: 0.1935 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.3462 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 6/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m562s\u001b[0m 347ms/step - loss: 0.1415 - sparse_categorical_accuracy: 0.9679 - val_loss: 0.3432 - val_sparse_categorical_accuracy: 0.9468\n",
            "Epoch 7/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 370ms/step - loss: 0.1093 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.3452 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 8/8\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 348ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9788 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.9476\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    [input_train, decoder_input_train],\n",
        "    np.expand_dims(decoder_target_train, -1),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(\n",
        "        [input_val, decoder_input_val],\n",
        "        np.expand_dims(decoder_target_val, -1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Gráfica de la pérdida y la precisión\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.legend()\n",
        "plt.title('Evolución de la pérdida')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Paso 1: Predecir etiquetas de clase\n",
        "y_pred_probs = model_lstm.predict(X_test_pad)  # Obtiene probabilidades de cada clase\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convierte a etiquetas enteras\n",
        "\n",
        "# Paso 2: Convertir y_test_one_hot a etiquetas enteras\n",
        "y_test_labels = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "# Paso 3: Generar la matriz de confusión\n",
        "cm = confusion_matrix(y_test_labels, y_pred)\n",
        "\n",
        "# Paso 4: Graficar la matriz de confusión\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test_labels), yticklabels=np.unique(y_test_labels))\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix - LSTM\")\n",
        "plt.show()\n",
        "\n",
        "# Reporte de clasificación (precisión, recall, F1-score)\n",
        "print(classification_report(y_test_labels, y_pred))\n"
      ],
      "metadata": {
        "id": "LabX8BBe2Ftz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD_2jEvR_bDd",
        "outputId": "605d78ce-c4cc-402f-d9ca-3f9d222eae15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado exitosamente en translation_model2.h5\n"
          ]
        }
      ],
      "source": [
        "# Guardar el modelo completo\n",
        "model.save('/content/drive/MyDrive/Deep Learning/Proyecto1/translation_model2.h5')\n",
        "print(\"Modelo guardado exitosamente en translation_model2.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXwGvMeHEMJS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcfdd618-4b2c-4766-fe76-b54d5b776497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/MyDrive/Deep Learning/Proyecto1/translation_model_lstm.h5')\n",
        "print(\"Modelo cargado exitosamente.\")\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Función para preprocesar el texto de entrada\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    # Convertir el texto en secuencias\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Función para generar traducción con el modelo entrenado\n",
        "def translate(model, input_text, input_tokenizer, target_tokenizer, max_input_length, max_target_length):\n",
        "    # Preprocesar el texto de entrada\n",
        "    input_seq = preprocess_input(input_text, input_tokenizer, max_input_length)\n",
        "\n",
        "    # Inicializar la secuencia de entrada del decodificador\n",
        "    decoder_input = np.zeros((1, max_target_length))  # Un batch de tamaño 1\n",
        "    decoder_input[0, 0] = target_tokenizer.word_index['<start>']\n",
        "\n",
        "    # Inicializar la salida\n",
        "    translated_sentence = \"\"\n",
        "\n",
        "    # Generar la traducción\n",
        "    for t in range(1, max_target_length):\n",
        "        # Hacer predicción\n",
        "        output = model.predict([input_seq, decoder_input])\n",
        "\n",
        "        # Obtener el índice de la palabra con la mayor probabilidad\n",
        "        predicted_id = np.argmax(output[0, t-1, :])\n",
        "\n",
        "        # Detener si se predice la palabra <end>\n",
        "        if predicted_id == target_tokenizer.word_index['<end>']:\n",
        "            break\n",
        "\n",
        "        # Convertir el índice en una palabra\n",
        "        predicted_word = target_tokenizer.index_word[predicted_id]\n",
        "        translated_sentence += \" \" + predicted_word\n",
        "\n",
        "        # Actualizar la entrada del decodificador\n",
        "        decoder_input[0, t] = predicted_id\n",
        "\n",
        "    # Eliminar espacios al inicio y al final\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "# Ejemplo de uso para traducir una lista de oraciones\n",
        "\n",
        "# Ingresar una lista de oraciones en inglés\n",
        "input_texts = [\n",
        "    \"what is your name\",\n",
        "    \"how are you\",\n",
        "    \"where do you live\",\n",
        "    \"what time is it\",\n",
        "    \"thank you very much\"\n",
        "]\n",
        "\n",
        "# Traducir cada oración de la lista\n",
        "for input_text in input_texts:\n",
        "    translated_text = translate(model, input_text, tokenizer_eng, tokenizer_spa,\n",
        "                                max_input_length=input_train.shape[1], max_target_length=target_train.shape[1])\n",
        "\n",
        "    print(f\"Texto en inglés: {input_text}\")\n",
        "    print(f\"Traducción al español: {translated_text}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odi1UMeI9Sef",
        "outputId": "ecce1d81-be02-4c0f-d65c-1da052e284f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Texto en inglés: what is your name\n",
            "Traducción al español: ¿qué es tu nombre.\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "Texto en inglés: how are you\n",
            "Traducción al español: ¿cómo te sientes?\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "Texto en inglés: where do you live\n",
            "Traducción al español: ¿dónde vive usted el sitio?\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
            "Texto en inglés: what time is it\n",
            "Traducción al español: ¿qué hora es él?\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
            "Texto en inglés: thank you very much\n",
            "Traducción al español: muchísimas mucho.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRsW9Tl0B0eI",
        "outputId": "389f72b9-9284-4e3f-ff60-efab296d990c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "#model = load_model('/content/drive/MyDrive/Deep Learning/Proyecto1/translation_model2.h5', custom_objects={'Attention': Attention})\n",
        "#print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "# Cargar el dataset para obtener las frases (asegúrate de cargarlo correctamente desde tu archivo)\n",
        "#dataset = pd.read_csv('/content/drive/MyDrive/Deep Learning/Proyecto1/data.csv')\n",
        "\n",
        "# Tokenización para inglés\n",
        "input_texts = dataset['english'].values\n",
        "tokenizer_eng = Tokenizer(filters='')\n",
        "tokenizer_eng.fit_on_texts(input_texts)\n",
        "\n",
        "# Tokenización para español\n",
        "target_texts = ['<start> ' + text + ' <end>' for text in dataset['spanish'].values]\n",
        "tokenizer_spa = Tokenizer(filters='')\n",
        "tokenizer_spa.fit_on_texts(target_texts)\n",
        "\n",
        "# Preprocesamiento de entrada para el modelo\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Función para la traducción\n",
        "def translate(input_text):\n",
        "    # Preprocesar el texto de entrada\n",
        "    input_sequence = preprocess_input(input_text, tokenizer_eng, max_length=10)  # Ajusta max_length según el modelo\n",
        "\n",
        "    # Crear el input para el decoder (usamos <start> para el inicio)\n",
        "    decoder_input = np.array([[tokenizer_spa.word_index['<start>']]])\n",
        "\n",
        "    # Lista para almacenar las palabras generadas\n",
        "    translated_words = []\n",
        "\n",
        "    for _ in range(10):  # Limita la cantidad de palabras generadas\n",
        "        output_tokens = model.predict([input_sequence, decoder_input])\n",
        "\n",
        "        # Obtener la palabra más probable\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer_spa.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        # Si el modelo predice <end>, detenemos la generación\n",
        "        if sampled_word == '<end>' or sampled_word in translated_words:\n",
        "            break\n",
        "\n",
        "        translated_words.append(sampled_word)\n",
        "\n",
        "        # Actualizar el input del decoder\n",
        "        decoder_input = np.array([[sampled_token_index]])\n",
        "\n",
        "    return \" \".join(translated_words).strip()\n",
        "\n",
        "# Crear la interfaz de usuario con Gradio\n",
        "iface = gr.Interface(fn=translate, inputs=\"text\", outputs=\"text\", title=\"Traducción de Inglés a Español\",\n",
        "                     description=\"Introduce una frase en inglés y obtén la traducción al español.\")\n",
        "\n",
        "# Lanzar la interfaz de usuario\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "R15ipvo0BxcP",
        "outputId": "765af956-ed47-4257-dbc9-657ac22376c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f9cb3b355e859b3dd6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f9cb3b355e859b3dd6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "XwRZg9PuiEvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, Reshape, MultiHeadAttention, GlobalAveragePooling1D, TimeDistributed\n",
        "from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QttcMLvskXXe",
        "outputId": "510d105d-5323-413f-a2bb-c20a3f4908ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Deep Learning/Proyecto1/data.csv\")"
      ],
      "metadata": {
        "id": "YsT0VQphkcwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros globales\n",
        "LATENT_DIM = 256\n",
        "input_vocab_size = 23849  # Tamaño del vocabulario en inglés\n",
        "target_vocab_size = 41724  # Tamaño del vocabulario en español\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 5\n",
        "\n",
        "# Verificar valores nulos\n",
        "if dataset.isnull().sum().any():\n",
        "    print(\"Advertencia: Existen valores nulos en el dataset.\")\n",
        "    dataset = dataset.dropna()\n",
        "else:\n",
        "    print(\"No se encontraron valores nulos.\")\n",
        "\n",
        "# Previsualizar datos\n",
        "print(\"\\nEjemplo de datos:\")\n",
        "print(dataset.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl440eFrkfIY",
        "outputId": "1b798a13-905f-4367-f439-d9b98097dfdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron valores nulos.\n",
            "\n",
            "Ejemplo de datos:\n",
            "  english  spanish\n",
            "0     Go.      Ve.\n",
            "1     Go.    Vete.\n",
            "2     Go.    Vaya.\n",
            "3     Go.  Váyase.\n",
            "4     Hi.    Hola.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preparar los datos\n",
        "input_texts = dataset['english'].values\n",
        "target_texts = ['<start> ' + text + ' <end>' for text in dataset['spanish'].values]\n",
        "\n",
        "# Tokenización para inglés\n",
        "tokenizer_eng = Tokenizer(filters='')\n",
        "tokenizer_eng.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_eng.texts_to_sequences(input_texts)\n",
        "input_sequences = pad_sequences(input_sequences, padding='post')\n",
        "\n",
        "# Tokenización para español\n",
        "tokenizer_spa = Tokenizer(filters='')\n",
        "tokenizer_spa.fit_on_texts(target_texts)\n",
        "target_sequences = tokenizer_spa.texts_to_sequences(target_texts)\n",
        "target_sequences = pad_sequences(target_sequences, padding='post')\n",
        "\n",
        "# Vocabulario\n",
        "input_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "target_vocab_size = len(tokenizer_spa.word_index) + 1\n",
        "\n",
        "print(f\"Tamaño del vocabulario (inglés): {input_vocab_size}\")\n",
        "print(f\"Tamaño del vocabulario (español): {target_vocab_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjAN4pVYklwn",
        "outputId": "1ca9aa00-0432-4042-95ed-3dc2234ac43c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del vocabulario (inglés): 23849\n",
            "Tamaño del vocabulario (español): 41724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir datos en entrenamiento y validación\n",
        "input_train, input_val, target_train, target_val = train_test_split(\n",
        "    input_sequences, target_sequences, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Crear entradas y salidas para el decodificador\n",
        "decoder_input_train = np.array([seq[:-1] for seq in target_train])\n",
        "decoder_target_train = np.array([seq[1:] for seq in target_train])\n",
        "decoder_input_val = np.array([seq[:-1] for seq in target_val])\n",
        "decoder_target_val = np.array([seq[1:] for seq in target_val])\n",
        "\n",
        "# Construcción del modelo Transformer\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_vocab_size, LATENT_DIM)(encoder_inputs)\n",
        "encoder_attention = MultiHeadAttention(num_heads=8, key_dim=LATENT_DIM)(encoder_embedding, encoder_embedding)\n",
        "encoder_attention = LayerNormalization()(encoder_attention)\n",
        "encoder_attention = Dropout(0.1)(encoder_attention)\n",
        "\n",
        "# Reshape para asegurar las 3 dimensiones necesarias\n",
        "encoder_output = Reshape((-1, LATENT_DIM))(encoder_attention)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(target_vocab_size, LATENT_DIM)(decoder_inputs)\n",
        "\n",
        "# Asegurarse de que las entradas al decoder también tengan 3 dimensiones\n",
        "decoder_attention = MultiHeadAttention(num_heads=8, key_dim=LATENT_DIM)(decoder_embedding, encoder_output)\n",
        "decoder_attention = LayerNormalization()(decoder_attention)\n",
        "decoder_attention = Dropout(0.1)(decoder_attention)\n",
        "\n",
        "# Salida del decoder con TimeDistributed para secuencias\n",
        "decoder_output = TimeDistributed(Dense(target_vocab_size, activation='softmax'))(decoder_attention)\n",
        "\n",
        "# Modelo completo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "f_WAowo2kpej",
        "outputId": "97ef931d-53ae-4546-ccdb-fe5a54790ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m6,105,344\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m10,681,344\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention_… │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41724\u001b[0m)    │     \u001b[38;5;34m10,723,068\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,344</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,681,344</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41724</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,723,068</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,717,884\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,884</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,717,884\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,884</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    [input_train, decoder_input_train],\n",
        "    np.expand_dims(decoder_target_train, -1),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(\n",
        "        [input_val, decoder_input_val],\n",
        "        np.expand_dims(decoder_target_val, -1)\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "HRE9YRaElRua",
        "outputId": "f6d24caa-a215-4211-c9b5-99f51bf60e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-72dc02a42ab1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0minput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_target_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             outputs = self.distribute_strategy.run(\n\u001b[0m\u001b[1;32m    122\u001b[0m                 \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    338\u001b[0m   )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   concrete_function = concrete_function_lib.ConcreteFunction.from_func_graph(\n\u001b[0m\u001b[1;32m    341\u001b[0m       \u001b[0mtraced_func_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0mtraced_func_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36mfrom_func_graph\u001b[0;34m(cls, graph, function_type, attrs, shared_func_graph)\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_func_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_func_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m     atomic_fn = atomic_function.from_func_graph(\n\u001b[0m\u001b[1;32m   1076\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mfrom_func_graph\u001b[0;34m(name, graph, attrs, function_type, overwrite)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc_graph\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     fn = pywrap_tf_session.TF_GraphToFunction_wrapper(\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gráfica de la pérdida y la precisión\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.legend()\n",
        "plt.title('Evolución de la pérdida')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "RcnIQI_EiHoj",
        "outputId": "5ac7c277-9204-4d3c-a669-5d9648b65046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo completo en un archivo .h5\n",
        "model.save('/content/drive/MyDrive/Deep Learning/Proyecto1/modelo_transformer.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krYcsOeFrXEJ",
        "outputId": "87a0f710-928e-4ce0-8685-7959d7de2b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/MyDrive/Deep Learning/Proyecto1/modelo_transformer.h5')\n",
        "print(\"Modelo cargado exitosamente.\")\n",
        "#model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHNYK-GKgCv2",
        "outputId": "0533daf5-ed84-455d-aac0-77cabe4a2093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Función para preprocesar el texto de entrada\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    # Convertir el texto en secuencias\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Función para generar traducción con el modelo entrenado\n",
        "def translate(model, input_text, input_tokenizer, target_tokenizer, max_input_length, max_target_length):\n",
        "    # Preprocesar el texto de entrada\n",
        "    input_seq = preprocess_input(input_text, input_tokenizer, max_input_length)\n",
        "\n",
        "    # Inicializar la secuencia de entrada del decodificador\n",
        "    decoder_input = np.zeros((1, max_target_length))  # Un batch de tamaño 1\n",
        "    decoder_input[0, 0] = target_tokenizer.word_index['<start>']\n",
        "\n",
        "    # Inicializar la salida\n",
        "    translated_sentence = \"\"\n",
        "\n",
        "    # Generar la traducción\n",
        "    for t in range(1, max_target_length):\n",
        "        # Hacer predicción\n",
        "        output = model.predict([input_seq, decoder_input])\n",
        "\n",
        "        # Obtener el índice de la palabra con la mayor probabilidad (Top-1)\n",
        "        predicted_id = np.argmax(output[0, t-1, :])\n",
        "\n",
        "        # Detener si se predice la palabra <end>\n",
        "        if predicted_id == target_tokenizer.word_index['<end>']:\n",
        "            break\n",
        "\n",
        "        # Convertir el índice en una palabra\n",
        "        predicted_word = target_tokenizer.index_word[predicted_id]\n",
        "        translated_sentence += \" \" + predicted_word\n",
        "\n",
        "        # Actualizar la entrada del decodificador\n",
        "        decoder_input[0, t] = predicted_id\n",
        "\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "# Función para evaluar la traducción utilizando BLEU score\n",
        "def evaluate_translation(reference, candidate):\n",
        "    # Convertir las oraciones en listas de palabras\n",
        "    reference = [reference.split()]\n",
        "    candidate = candidate.split()\n",
        "\n",
        "    # Calcular el BLEU score\n",
        "    bleu_score = sentence_bleu(reference, candidate)\n",
        "    return bleu_score\n",
        "\n",
        "# Ejemplo de uso para realizar una prueba\n",
        "input_texts = [\n",
        "    \"what is your name\",\n",
        "    \"how are you\",\n",
        "    \"where do you live\",\n",
        "    \"what time is it\",\n",
        "    \"thank you very much\"\n",
        "]  # Lista de oraciones en inglés\n",
        "\n",
        "# Definir las traducciones de referencia en español (esto es solo un ejemplo)\n",
        "reference_texts = [\n",
        "    \"¿Cuál es tu nombre?\",\n",
        "    \"¿Cómo estás?\",\n",
        "    \"¿Dónde vives?\",\n",
        "    \"¿Qué hora es?\",\n",
        "    \"Muchas gracias\"\n",
        "]  # Las traducciones correctas en español\n",
        "\n",
        "# Realizar la traducción y evaluación para cada oración en input_texts\n",
        "for i, input_text in enumerate(input_texts):\n",
        "    # Realizar la traducción con el modelo (asegúrate de que el modelo y los tokenizadores estén definidos)\n",
        "    translated_text = translate(model, input_text, tokenizer_eng, tokenizer_spa,\n",
        "                                max_input_length=input_train.shape[1], max_target_length=target_train.shape[1])\n",
        "\n",
        "    # Imprimir resultados\n",
        "    print(f\"Texto en inglés: {input_text}\")\n",
        "    print(f\"Traducción al español: {translated_text}\")\n",
        "\n",
        "    # Evaluación de la traducción utilizando BLEU score\n",
        "    reference_text = reference_texts[i]  # Referencia correspondiente para esta oración\n",
        "    bleu_score = evaluate_translation(reference_text, translated_text)\n",
        "    print(f\"BLEU score: {bleu_score:.4f}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnzDZYnO9411",
        "outputId": "068f206a-dfca-43e4-9f46-6693ae924a36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "Texto en inglés: what is your name\n",
            "Traducción al español: ¿cuál es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es\n",
            "BLEU score: 0.0000\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
            "Texto en inglés: how are you\n",
            "Traducción al español: ¿cuántos estás en mí?\n",
            "BLEU score: 0.0000\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "Texto en inglés: where do you live\n",
            "Traducción al español: ¿dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive en dónde vive\n",
            "BLEU score: 0.0000\n",
            "--------------------------------------------------\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
            "Texto en inglés: what time is it\n",
            "Traducción al español: ¿a qué hora es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es tiempo es\n",
            "BLEU score: 0.0000\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step\n",
            "Texto en inglés: thank you very much\n",
            "Traducción al español: gracias por mucho afortunados.\n",
            "BLEU score: 0.0000\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Función para preprocesar el texto de entrada\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    # Convertir el texto en secuencias\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Función para generar traducción con el modelo entrenado\n",
        "def translate(model, input_text, input_tokenizer, target_tokenizer, max_input_length, max_target_length):\n",
        "    # Preprocesar el texto de entrada\n",
        "    input_seq = preprocess_input(input_text, input_tokenizer, max_input_length)\n",
        "\n",
        "    # Inicializar la secuencia de entrada del decodificador\n",
        "    decoder_input = np.zeros((1, max_target_length))  # Un batch de tamaño 1\n",
        "    decoder_input[0, 0] = target_tokenizer.word_index['<start>']\n",
        "\n",
        "    # Inicializar la salida\n",
        "    translated_sentence = \"\"\n",
        "\n",
        "    # Generar la traducción\n",
        "    for t in range(1, max_target_length):\n",
        "        # Hacer predicción\n",
        "        output = model.predict([input_seq, decoder_input])\n",
        "\n",
        "        # Obtener el índice de la palabra con la mayor probabilidad (Top-1)\n",
        "        predicted_id = np.argmax(output[0, t-1, :])\n",
        "\n",
        "        # Detener si se predice la palabra <end>\n",
        "        if predicted_id == target_tokenizer.word_index['<end>']:\n",
        "            break\n",
        "\n",
        "        # Convertir el índice en una palabra\n",
        "        predicted_word = target_tokenizer.index_word[predicted_id]\n",
        "        translated_sentence += \" \" + predicted_word\n",
        "\n",
        "        # Actualizar la entrada del decodificador\n",
        "        decoder_input[0, t] = predicted_id\n",
        "\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "# Función para evaluar la traducción utilizando BLEU score\n",
        "def evaluate_translation(reference, candidate):\n",
        "    # Convertir las oraciones en listas de palabras\n",
        "    reference = [reference.split()]\n",
        "    candidate = candidate.split()\n",
        "\n",
        "    # Calcular el BLEU score\n",
        "    bleu_score = sentence_bleu(reference, candidate)\n",
        "    return bleu_score\n",
        "\n",
        "# Ejemplo de uso para realizar una prueba\n",
        "input_texts = [\n",
        "    \"what is your name\"\n",
        "]  # Ingresar una oración en inglés\n",
        "\n",
        "# Realizar la traducción con el modelo (asegúrate de que el modelo y los tokenizadores estén definidos)\n",
        "# El modelo debe ser entrenado previamente, y `input_train`, `target_train` deben ser definidos.\n",
        "translated_text = translate(model, input_text, tokenizer_eng, tokenizer_spa,\n",
        "                            max_input_length=input_train.shape[1], max_target_length=target_train.shape[1])\n",
        "\n",
        "# Imprimir resultados\n",
        "print(f\"Texto en inglés: {input_text}\")\n",
        "print(f\"Traducción al español: {translated_text}\")\n",
        "\n",
        "# Evaluación de la traducción utilizando BLEU score\n",
        "reference_text = \"hola\"  # La traducción correcta de \"hello\" (en español)\n",
        "bleu_score = evaluate_translation(reference_text, translated_text)\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuZ4OcqJgJUg",
        "outputId": "37f33aaf-a29b-4d61-f2b3-60f202a55816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step\n",
            "Texto en inglés: what is your name \n",
            "Traducción al español: ¿cuál es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es tu nombre es\n",
            "BLEU score: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "Gq3H4jW1gpKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32efdc6-f7c0-428c-8b7c-e99b219fb0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.5)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model = load_model('/content/drive/MyDrive/Deep Learning/Proyecto1/modelo_transformer.h5', custom_objects={'Attention': Attention})\n",
        "print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "# Cargar el dataset para obtener las frases (asegúrate de cargarlo correctamente desde tu archivo)\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Deep Learning/Proyecto1/data.csv')\n",
        "\n",
        "# Tokenización para inglés\n",
        "input_texts = dataset['english'].values\n",
        "tokenizer_eng = Tokenizer(filters='')\n",
        "tokenizer_eng.fit_on_texts(input_texts)\n",
        "\n",
        "# Tokenización para español\n",
        "target_texts = ['<start> ' + text + ' <end>' for text in dataset['spanish'].values]\n",
        "tokenizer_spa = Tokenizer(filters='')\n",
        "tokenizer_spa.fit_on_texts(target_texts)\n",
        "\n",
        "# Preprocesamiento de entrada para el modelo\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "def translate(input_text, max_length=10, max_repeats=1):\n",
        "    # Preprocesar el texto de entrada\n",
        "    input_sequence = preprocess_input(input_text, tokenizer_eng, max_length)\n",
        "\n",
        "    # Crear el input para el decoder (usamos <start> para el inicio)\n",
        "    decoder_input = np.array([[tokenizer_spa.word_index['<start>']]])\n",
        "\n",
        "    # Predicción paso a paso\n",
        "    translated_sentence = ''\n",
        "    word_count = {}  # Diccionario para contar repeticiones de palabras\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Predecir la siguiente palabra\n",
        "        output_tokens = model.predict([input_sequence, decoder_input], verbose=0)\n",
        "\n",
        "        # Obtener la palabra más probable\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_word = tokenizer_spa.index_word.get(sampled_token_index, '')\n",
        "\n",
        "        # Si se encuentra la palabra <end>, detener la generación\n",
        "        if sampled_word == '<end>':\n",
        "            break\n",
        "\n",
        "        # Evitar que una palabra se repita más de `max_repeats` veces\n",
        "        if sampled_word in word_count:\n",
        "            if word_count[sampled_word] >= max_repeats:\n",
        "                continue  # Saltar esta palabra si ya se ha repetido demasiado\n",
        "            word_count[sampled_word] += 1\n",
        "        else:\n",
        "            word_count[sampled_word] = 1\n",
        "\n",
        "        # Añadir la palabra al resultado\n",
        "        translated_sentence += ' ' + sampled_word\n",
        "\n",
        "        # Actualizar el input del decoder\n",
        "        decoder_input = np.hstack([decoder_input, np.array([[sampled_token_index]])])\n",
        "\n",
        "    return translated_sentence.strip()\n",
        "\n",
        "# Crear la interfaz de usuario con Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=translate,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"Traducción de Inglés a Español\",\n",
        "    description=\"Introduce una frase en inglés y obtén la traducción al español.\"\n",
        ")\n",
        "\n",
        "# Lanzar la interfaz de usuario\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "Veh0NSYNgtAF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "77662b5f-7c7c-484b-b93a-fb99e4373736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5206058562704ce411.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5206058562704ce411.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRANSFORMER 2"
      ],
      "metadata": {
        "id": "3NmogQEu0Lpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RslByXkmqbFJ",
        "outputId": "38f6c5c6-b01e-4881-8891-e11f8d740d19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, LayerNormalization, Dropout, Reshape, MultiHeadAttention, GlobalAveragePooling1D, TimeDistributed\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Cargar datos\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/Deep learning01/data.csv\")\n",
        "\n",
        "# Verificar valores nulos\n",
        "if dataset.isnull().sum().any():\n",
        "    print(\"Advertencia: Existen valores nulos en el dataset.\")\n",
        "    dataset = dataset.dropna()\n",
        "else:\n",
        "    print(\"No se encontraron valores nulos.\")\n",
        "\n",
        "# Previsualizar datos\n",
        "print(\"\\nEjemplo de datos:\")\n",
        "print(dataset.head())\n",
        "\n",
        "# Preparar los datos\n",
        "input_texts = dataset['english'].values\n",
        "target_texts = ['<start> ' + text + ' <end>' for text in dataset['spanish'].values]\n",
        "\n",
        "# Tokenización para inglés\n",
        "tokenizer_eng = Tokenizer(filters='')\n",
        "tokenizer_eng.fit_on_texts(input_texts)\n",
        "input_sequences = tokenizer_eng.texts_to_sequences(input_texts)\n",
        "input_sequences = pad_sequences(input_sequences, padding='post')\n",
        "\n",
        "# Tokenización para español\n",
        "tokenizer_spa = Tokenizer(filters='')\n",
        "tokenizer_spa.fit_on_texts(target_texts)\n",
        "target_sequences = tokenizer_spa.texts_to_sequences(target_texts)\n",
        "target_sequences = pad_sequences(target_sequences, padding='post')\n",
        "\n",
        "# Vocabulario\n",
        "input_vocab_size = len(tokenizer_eng.word_index) + 1\n",
        "target_vocab_size = len(tokenizer_spa.word_index) + 1\n",
        "\n",
        "print(f\"Tamaño del vocabulario (inglés): {input_vocab_size}\")\n",
        "print(f\"Tamaño del vocabulario (español): {target_vocab_size}\")\n",
        "\n",
        "# Dividir datos en entrenamiento y validación\n",
        "input_train, input_val, target_train, target_val = train_test_split(\n",
        "    input_sequences, target_sequences, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Crear entradas y salidas para el decodificador\n",
        "decoder_input_train = np.array([seq[:-1] for seq in target_train])\n",
        "decoder_target_train = np.array([seq[1:] for seq in target_train])\n",
        "decoder_input_val = np.array([seq[:-1] for seq in target_val])\n",
        "decoder_target_val = np.array([seq[1:] for seq in target_val])\n",
        "\n",
        "# Construcción del modelo Transformer\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
        "encoder_attention = MultiHeadAttention(num_heads=8, key_dim=256)(encoder_embedding, encoder_embedding)\n",
        "encoder_attention = LayerNormalization()(encoder_attention)\n",
        "encoder_attention = Dropout(0.1)(encoder_attention)\n",
        "encoder_output = Reshape((-1, 256))(encoder_attention)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_embedding = Embedding(target_vocab_size, 256)(decoder_inputs)\n",
        "decoder_attention = MultiHeadAttention(num_heads=8, key_dim=256)(decoder_embedding, encoder_output)\n",
        "decoder_attention = LayerNormalization()(decoder_attention)\n",
        "decoder_attention = Dropout(0.1)(decoder_attention)\n",
        "decoder_output = TimeDistributed(Dense(target_vocab_size, activation='softmax'))(decoder_attention)\n",
        "\n",
        "# Modelo completo\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Callbacks\n",
        "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
        "callbacks = [checkpoint, early_stopping, reduce_lr]\n",
        "\n",
        "# Entrenamiento\n",
        "history = model.fit(\n",
        "    [input_train, decoder_input_train], decoder_target_train,\n",
        "    validation_data=([input_val, decoder_input_val], decoder_target_val),\n",
        "    batch_size=64, epochs=12, callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-PNMHz5vqUvn",
        "outputId": "3f880cf7-550b-4770-e923-db4f5e4c9d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No se encontraron valores nulos.\n",
            "\n",
            "Ejemplo de datos:\n",
            "  english  spanish\n",
            "0     Go.      Ve.\n",
            "1     Go.    Vete.\n",
            "2     Go.    Vaya.\n",
            "3     Go.  Váyase.\n",
            "4     Hi.    Hola.\n",
            "Tamaño del vocabulario (inglés): 23849\n",
            "Tamaño del vocabulario (español): 41724\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m6,105,344\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m10,681,344\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention_… │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41724\u001b[0m)    │     \u001b[38;5;34m10,723,068\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,344</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,681,344</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41724</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,723,068</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,717,884\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,884</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,717,884\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,884</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - loss: 1.6235 - sparse_categorical_accuracy: 0.8596"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 251ms/step - loss: 1.6231 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.7696 - val_sparse_categorical_accuracy: 0.8929 - learning_rate: 0.0010\n",
            "Epoch 2/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.7313 - sparse_categorical_accuracy: 0.8959"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 239ms/step - loss: 0.7313 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.9030 - learning_rate: 0.0010\n",
            "Epoch 3/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.5957 - sparse_categorical_accuracy: 0.9091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 240ms/step - loss: 0.5957 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.5892 - val_sparse_categorical_accuracy: 0.9109 - learning_rate: 0.0010\n",
            "Epoch 4/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.4885 - sparse_categorical_accuracy: 0.9193"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 241ms/step - loss: 0.4885 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.5385 - val_sparse_categorical_accuracy: 0.9166 - learning_rate: 0.0010\n",
            "Epoch 5/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.9262"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 244ms/step - loss: 0.4130 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.5074 - val_sparse_categorical_accuracy: 0.9205 - learning_rate: 0.0010\n",
            "Epoch 6/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.9324"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 243ms/step - loss: 0.3503 - sparse_categorical_accuracy: 0.9324 - val_loss: 0.4868 - val_sparse_categorical_accuracy: 0.9236 - learning_rate: 0.0010\n",
            "Epoch 7/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.9383"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 242ms/step - loss: 0.3019 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.4797 - val_sparse_categorical_accuracy: 0.9258 - learning_rate: 0.0010\n",
            "Epoch 8/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - loss: 0.2638 - sparse_categorical_accuracy: 0.9438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 229ms/step - loss: 0.2638 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.4706 - val_sparse_categorical_accuracy: 0.9270 - learning_rate: 0.0010\n",
            "Epoch 9/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9483"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 227ms/step - loss: 0.2368 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.4658 - val_sparse_categorical_accuracy: 0.9286 - learning_rate: 0.0010\n",
            "Epoch 10/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - loss: 0.2145 - sparse_categorical_accuracy: 0.9519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 238ms/step - loss: 0.2145 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.4638 - val_sparse_categorical_accuracy: 0.9293 - learning_rate: 0.0010\n",
            "Epoch 11/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 234ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.4656 - val_sparse_categorical_accuracy: 0.9302 - learning_rate: 0.0010\n",
            "Epoch 12/12\n",
            "\u001b[1m1488/1488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 221ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9576 - val_loss: 0.4670 - val_sparse_categorical_accuracy: 0.9310 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar el modelo completo\n",
        "model.save('/content/drive/MyDrive/Deep learning01/best_model_transformer.h5')\n",
        "\n",
        "print(\"Modelo guardado exitosamente en Google Drive.\")\n"
      ],
      "metadata": {
        "id": "ovIHHljA1axo",
        "outputId": "a4a80ded-41e3-4461-8358-21c2079893dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo guardado exitosamente en Google Drive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Cargar el modelo guardado\n",
        "model_loaded = load_model('/content/drive/MyDrive/Deep learning01/best_model_transformer.h5')\n",
        "\n",
        "# Verificar la estructura del modelo cargado\n",
        "model_loaded.summary()\n"
      ],
      "metadata": {
        "id": "JpGYTrMN2Efv",
        "outputId": "a9448fea-2ed4-4fad-85df-180b93287424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m6,105,344\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m10,681,344\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m2,103,552\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ multi_head_attention_… │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41724\u001b[0m)    │     \u001b[38;5;34m10,723,068\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,105,344</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,681,344</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,103,552</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ multi_head_attention_… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41724</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,723,068</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,717,886\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,886</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,717,884\u001b[0m (120.99 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,717,884</span> (120.99 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    \"\"\"Convierte el texto en una secuencia de enteros y la paddea.\"\"\"\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Modificación de la función translate()\n",
        "def translate(model, input_text, input_tokenizer, target_tokenizer, max_input_length, max_target_length):\n",
        "    input_seq = preprocess_input(input_text, input_tokenizer, max_input_length)\n",
        "    decoder_input = np.zeros((1, max_target_length))\n",
        "    decoder_input[0, 0] = target_tokenizer.word_index['<start>']\n",
        "\n",
        "    translated_sentence = []\n",
        "    seen_words = set()  # Para evitar repeticiones\n",
        "\n",
        "    for t in range(1, max_target_length):\n",
        "        output = model.predict([input_seq, decoder_input])\n",
        "        predicted_id = np.argmax(output[0, t-1, :])\n",
        "\n",
        "        # Detener si predice '<end>' o si la palabra ya se repitió muchas veces\n",
        "        if predicted_id == target_tokenizer.word_index['<end>'] or predicted_id in seen_words:\n",
        "            break\n",
        "\n",
        "        predicted_word = target_tokenizer.index_word.get(predicted_id, \"\")\n",
        "        translated_sentence.append(predicted_word)\n",
        "        seen_words.add(predicted_id)  # Agregar palabra al conjunto de palabras vistas\n",
        "\n",
        "        # Actualizar la entrada del decodificador\n",
        "        decoder_input[0, t] = predicted_id\n",
        "\n",
        "    return \" \".join(translated_sentence)\n",
        "\n",
        "def evaluate_translation(reference, candidate):\n",
        "    \"\"\"Calcula el BLEU score para evaluar la calidad de la traducción.\"\"\"\n",
        "    reference = [reference.split()]\n",
        "    candidate = candidate.split()\n",
        "    return sentence_bleu(reference, candidate)\n",
        "\n",
        "# Prueba con un ejemplo\n",
        "test_sentence = \"what is your name\"\n",
        "translated_text = translate(model, test_sentence, tokenizer_eng, tokenizer_spa,\n",
        "                            max_input_length=input_train.shape[1], max_target_length=target_train.shape[1])\n",
        "\n",
        "print(f\"Texto en inglés: {test_sentence}\")\n",
        "print(f\"Traducción al español: {translated_text}\")\n",
        "\n",
        "reference_text = \"¿cuál es tu nombre?\"\n",
        "bleu_score = evaluate_translation(reference_text, translated_text)\n",
        "print(f\"BLEU score: {bleu_score}\")\n"
      ],
      "metadata": {
        "id": "UbYm0-2z8o49",
        "outputId": "3c96f1fe-1ad4-4358-df0b-9b378e5d0807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Texto en inglés: what is your name\n",
            "Traducción al español: ¿cuál es tu nombre\n",
            "BLEU score: 8.636168555094496e-78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "id": "wN7e-oz09ciI",
        "outputId": "1f8c47c8-a1f7-4fff-a9f8-a124bb97fe88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.15.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.7.0 (from gradio)\n",
            "  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.15.0-py3-none-any.whl (57.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.8 ffmpy-0.5.0 gradio-5.15.0 gradio-client-1.7.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Attention\n",
        "\n",
        "\n",
        "\n",
        "# Longitudes máximas\n",
        "MAX_INPUT_LENGTH = 20\n",
        "MAX_TARGET_LENGTH = 20\n",
        "\n",
        "# Función para preprocesar la entrada\n",
        "def preprocess_input(text, tokenizer, max_length):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    seq = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    return seq\n",
        "\n",
        "# Función corregida para traducción\n",
        "def translate(input_text, max_length=MAX_TARGET_LENGTH, max_repeats=1):\n",
        "    input_sequence = preprocess_input(input_text, tokenizer_eng, MAX_INPUT_LENGTH)\n",
        "    decoder_input = np.array([[tokenizer_spa.word_index['<start>']]])\n",
        "\n",
        "    translated_sentence = []\n",
        "    word_count = {}\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        output_tokens = model.predict([input_sequence, decoder_input], verbose=0)\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        # Obtener la palabra y manejar errores\n",
        "        sampled_word = tokenizer_spa.index_word.get(sampled_token_index, '')\n",
        "        if not sampled_word or sampled_word == '<end>':\n",
        "            break\n",
        "\n",
        "        # Evitar repeticiones\n",
        "        word_count[sampled_word] = word_count.get(sampled_word, 0) + 1\n",
        "        if word_count[sampled_word] > max_repeats:\n",
        "            continue\n",
        "\n",
        "        translated_sentence.append(sampled_word)\n",
        "        decoder_input = np.hstack([decoder_input, np.array([[sampled_token_index]])])\n",
        "\n",
        "        # 🔴 **Prevención de bucles infinitos**: Romper si el input del decoder se hace demasiado largo\n",
        "        if decoder_input.shape[1] >= max_length:\n",
        "            break\n",
        "\n",
        "    return \" \".join(translated_sentence) if translated_sentence else \"⚠ No se pudo generar la traducción.\"\n",
        "\n",
        "# Crear interfaz Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=translate,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Escribe en inglés...\"),\n",
        "    outputs=gr.Textbox(label=\"Traducción al Español\"),\n",
        "    title=\"🌍 Traductor IA Inglés ➝ Español\",\n",
        "    description=\"Escribe una oración en inglés y obtén su traducción en español.\",\n",
        "    theme=\"default\"\n",
        ")\n",
        "\n",
        "# Ejecutar interfaz\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "ju26htaRAVQS",
        "outputId": "85a1b852-a60d-4e73-eab1-0254fe41a212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4a56c54f4c6692c3dc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4a56c54f4c6692c3dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}